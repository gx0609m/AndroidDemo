HashMap
    背景
        由于
            ——— 数组 查找快、增删慢；
            ——— 链表 查找慢、增删快；
        因此，Java中使用了 HashMap 来综合这两者的优点；

    简介
        HashMap 这种数据结构
            ——— 一般的，实现哈希表的方法为“拉链法”，我们可以理解为“链表的数组”，也就是一个数组里面有多个链表，即  一个HashMap = 1个数组 + n个链表；
            ——— 综合了 数组&链表 的优势，具有较快（常量级）的查询速度，及相对较快的增删速度，适合在海量数据的环境中使用；

        结构图如下：
            ——— res\summarychart\hashMap_structure.png；

    原理
        我们知道，HashMap的K值是唯一的，那如何保证唯一性呢？
            ——— 首先想到的是用equals()比较，没错，这样可以实现，但随着内部元素的增多，put和get的效率将越来越低；
            ——— 例如，有1000个元素，put时最差情况需要比较1000次，这样的话时间复杂度就会是O(n)；
        而实际上，HashMap很少（只有在发生碰撞时才）会用到equals()方法，因为其内部是通过一个哈希表管理所有元素的；

        HashMap中常用的方法是put(k,v)，get(k)，我们以 put(k,v)方法 为例，梳理下过程；
        当我们调用put(k,v)存值时：
            ——— HashMap首先会调用 k的hashCode() 方法，获取 k的hash码 ，通过哈希码快速定位到在 数组中的位置 ，这个位置可以称为bucketIndex（桶索引）；

            ——— 如果在这个 bucketIndex 上还没有存放 元素（Entry：键值对），则直接将这个 k 和 k所对应的v 作为一个Entry放入这个 桶索引 指向的链表中；

            ——— 如果在这个 bucketIndex 上已经存在了由 一个或多个Entry 组成的链表，这时就会发生 碰撞；
                （这里的碰撞可以理解为 k所计算得到的hashCode值 的碰撞，因为根据这个值找到了相同的 bucketIndex，而这个 bucketIndex指向的链表 上已存在了 Entry）

            ——— 此时，就需要通过 equals() 方法来将 要存入的v值（新v值） 与 链表中已存在的每个Entry的v值（老v值） 进行比较（遍历链表比较v值），
                    ——— 如果相等，则用 新v值替换老v值，并将老v值作为put方法的返回值返回；
                    ——— 如果不相等，则将这个 新v值所在的Entry 放入 bucketIndex所指向的链表的头部（头插法）；
        到这里，HashMap的 put(k,v) 过程就说明完毕了；

    构造方法
        HashMap一共重载了4个构造方法，分别为：
            a.HashMap()
              构造一个具有默认初始容量 (16) 和默认加载因子 (0.75) 的空 HashMap；

            b.HashMap(int initialCapacity)
              构造一个带指定初始容量和默认加载因子 (0.75) 的空 HashMap；

            c.HashMap(int initialCapacity, float loadFactor)
              构造一个带指定初始容量和加载因子的空 HashMap；

            d.HashMap(Map<? extendsK,? extendsV> m)
              构造一个映射关系与指定 Map 相同的 HashMap；

        a，b，d 构造方法最终都是调用 c 构造方法，我们来看下 c 构造方法的源码：
            public HashMap(int initialCapacity, float loadFactor) {
                // 参数判断，不合法抛出运行时异常
                if (initialCapacity < 0)
                    throw new IllegalArgumentException("Illegal initial capacity: " +
                                                       initialCapacity);
                if (initialCapacity > MAXIMUM_CAPACITY)
                    initialCapacity = MAXIMUM_CAPACITY;
                if (loadFactor <= 0 || Float.isNaN(loadFactor))
                    throw new IllegalArgumentException("Illegal load factor: " +
                                                       loadFactor);

                // Find a power of 2 >= initialCapacity
                // 注意一下，这里做了一个移位运算，保证了初始容量一定为2的幂，例如你传的是5，那么最终的容量会是8
                int capacity = 1;
                while (capacity < initialCapacity)
                    capacity <<= 1;

                // 设置加载因子
                this.loadFactor = loadFactor;
                // 设置下次扩容临界值
                threshold = (int)Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1);
                // 初始化哈希表
                table = new Entry[capacity];
                useAltHashing = sun.misc.VM.isBooted() &&
                        (capacity >= Holder.ALTERNATIVE_HASHING_THRESHOLD);
                init();
            }

    参数
        HashMap有 两个参数 影响其性能：初始容量 & 加载因子，默认初始容量为16，默认加载因子为0.75；
            ——— 容量是哈希表中 桶（bucket） 的数量；
            ——— 初始容量 只是哈希表 在创建时 的容量；
            ——— 加载因子 是哈希表在其容量自动增加之前可以达到多满的一种 尺度 ；
            ——— 当哈希表中的 条目数（要存放的元素个数） 超出了 加载因子*当前容量 时，会调用 rehash 方法将容量翻倍；

    成员变量
         HashMap中定义的 成员变量 如下：
            /**
             * The default initial capacity - MUST be a power of two.
             */
            static final int DEFAULT_INITIAL_CAPACITY = 16;// 默认初始容量为16，必须为2的幂

            /**
             * The maximum capacity, used if a higher value is implicitly specified
             * by either of the constructors with arguments.
             * MUST be a power of two <= 1<<30.
             */
            static final int MAXIMUM_CAPACITY = 1 << 30;// 最大容量为2的30次方

            /**
             * The load factor used when none specified in constructor.
             */
            static final float DEFAULT_LOAD_FACTOR = 0.75f;// 默认加载因子0.75

            /**
             * The table, resized as necessary. Length MUST Always be a power of two.
             */
            transient Entry<K,V>[] table;// Entry数组，哈希表，长度必须为2的幂

            /**
             * The number of key-value mappings contained in this map.
             */
            transient int size;// 已存元素的个数（当前HashMap中已存储的 键值对 数量）

            /**
             * The next size value at which to resize (capacity * load factor).
             * @serial
             */
            int threshold;// 下次扩容的临界值，size>=threshold就会扩容

            /**
             * The load factor for the hash table.
             *
             * @serial
             */
            final float loadFactor;// 加载因子

    问题
        1.为什么 HashMap 的容量（capacity ） 一定要为2的幂呢？
        答：
          代码中好像并无详细说明，但估计和 源码中以及一些底层代码 在运算时使用 位运算 有关；

        2.在 多线程 下使用HashMap需要怎么做？
        答：
          a.在外部包装HashMap，实现同步机制；
          b.使用 Map m = Collections.synchronizedMap(new HashMap(...));，这里就是对HashMap做了一次包装；
          c.使用 java.util.HashTable，效率最低；
          d.使用 java.util.concurrent.ConcurrentHashMap，相对安全，效率较高；

        3.加载因子 越大越好吗？
        答：
          加载因子是在 时间&空间 成本上寻求一种折衷，加载因子过高虽然会减少空间开销，但同时也增加了查询成本；
          因为 加载因子 过大，会导致 散列的密度 更大，即链表更长，而在长链表中进行查询操作显然会更慢；

        4.JDK 1.8 对 HashMap和ConcurrentHashMap 的 底层数据结构 做了哪些修改？


HashTable
    背景
        HashMap中的方法是 非线程安全 的，多线程环境中的HashMap并不适用；


ConcurrentHashMap
    背景
        ConcurrentHashMap中的方法与HashTable中的一样，是线程安全的；
        不同的是，锁的粒度 以及 如何锁；

        都可以用于多线程的环境，但是当HashTable的大小增加到一定的时候，性能会急剧下降，因为迭代时需要被锁定很长的时间。因为ConcurrentHashMap引入了分割(segmentation)，不论它变得多么大，仅仅需要锁定map的某个部分，而其它的线程不需要等到迭代完成才能访问map。简而言之，在迭代的过程中，ConcurrentHashMap仅仅锁定map的某个部分，而Hashtable则会锁定整个map

    简介
        结构图如下：
            ——— res\summarychart\concurrentHashMap.png；

比较
    HashMap & HashTable
        相同点
            采用的 hash/rehash 算法都大概一样；

        区别
            ——— HashMap 允许将null作为一个entry的 key或者value ，而 HashTable 不允许；
            ——— HashMap 中的方法是 非线程安全 的，而 HashTable 中的方法是 线程安全 的，这也就会造成 HashMap 在 单线程的使用效率上 要高于HashTable；

    HashTable & ConcurrentHashMap
        相同点
            类中的方法都是线程安全的，都可以用于 多线程 环境下；

        区别
            ——— HashTable的大小增加到一定的时候，性能会急剧下降，因为迭代时需要被锁定很长的时间；
            ——— ConcurrentHashMap引入了 段（segment） 的概念，不论它变得多么大，仅仅需要锁定map的某个部分，而其它的线程不需要等到迭代完成才能访问map；

            简而言之，在迭代的过程中，ConcurrentHashMap仅仅锁定map的某个部分，而HashTable则会锁定整个map；

            它们两者的 主要区别 就是围绕着 锁的粒度 以及 如何锁，如下：
                ——— HashTable 锁 整个hash表；
                ——— ConcurrentHashMap 锁 segment（段/桶），ConcurrentHashMap会将hash表分为16（默认值）个segment；

            比较图如下：
                ——— res\summarychart\hashTable_concurrentHashMap.jpg；







（https://blog.csdn.net/ghsau/article/details/16843543）
（https://www.imooc.com/article/details/id/19737）
（https://blog.csdn.net/lsgqjh/article/details/54867107  JDK 1.8）
（https://blog.csdn.net/u011258318/article/details/45116877）
（https://www.cnblogs.com/wang-meng/p/5808006.html）